{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning the weights\n",
    "In this section, we'll unfreeze the pre-trained weights of the network and allow them to change.  \n",
    "Be careful - when fine-tuning a network, there is a risk that our attempt to allow the network to adapt to the new domain will lead to a \"catastrophic forgetting\" of what it had previously learnt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import models\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=NUM_WORKERS)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "def evaluate_net(net):\n",
    "\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images.to(device))\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            c = (predicted == labels.to(device)).squeeze()\n",
    "\n",
    "            for i in range(BATCH_SIZE):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "    [print(f'Accuracy of {c}: \\t {100 * class_correct[j] / class_total[j]}%') \n",
    "     for j, c in enumerate(classes)];\n",
    "\n",
    "    print('\\nAccuracy of the network on the 10000 test images:',  \n",
    "          f'{100 * np.sum(class_correct) / np.sum(class_total)}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\t iter: 1000\t loss:1.09049\n",
      "epoch: 1\t iter: 2000\t loss:0.72312\n",
      "epoch: 1\t iter: 3000\t loss:0.65535\n",
      "epoch: 1\t iter: 4000\t loss:0.60588\n",
      "epoch: 1\t iter: 5000\t loss:0.57770\n",
      "epoch: 1\t iter: 6000\t loss:0.53489\n",
      "epoch: 2\t iter: 1000\t loss:0.39499\n",
      "epoch: 2\t iter: 2000\t loss:0.38161\n",
      "epoch: 2\t iter: 3000\t loss:0.37437\n",
      "epoch: 2\t iter: 4000\t loss:0.38248\n",
      "epoch: 2\t iter: 5000\t loss:0.37894\n",
      "epoch: 2\t iter: 6000\t loss:0.36569\n",
      "epoch: 3\t iter: 1000\t loss:0.24428\n",
      "epoch: 3\t iter: 2000\t loss:0.24047\n",
      "epoch: 3\t iter: 3000\t loss:0.25715\n",
      "epoch: 3\t iter: 4000\t loss:0.26471\n",
      "epoch: 3\t iter: 5000\t loss:0.26122\n",
      "epoch: 3\t iter: 6000\t loss:0.26604\n",
      "epoch: 4\t iter: 1000\t loss:0.15247\n",
      "epoch: 4\t iter: 2000\t loss:0.19329\n",
      "epoch: 4\t iter: 3000\t loss:0.19426\n",
      "epoch: 4\t iter: 4000\t loss:0.19091\n",
      "epoch: 4\t iter: 5000\t loss:0.19062\n",
      "epoch: 4\t iter: 6000\t loss:0.18254\n",
      "Finished Training\n",
      "Accuracy of plane: \t 87.6%\n",
      "Accuracy of car: \t 94.0%\n",
      "Accuracy of bird: \t 83.2%\n",
      "Accuracy of cat: \t 83.0%\n",
      "Accuracy of deer: \t 78.7%\n",
      "Accuracy of dog: \t 77.0%\n",
      "Accuracy of frog: \t 91.2%\n",
      "Accuracy of horse: \t 92.9%\n",
      "Accuracy of ship: \t 96.3%\n",
      "Accuracy of truck: \t 92.2%\n",
      "\n",
      "Accuracy of the network on the 10000 test images: 87.61%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = models.vgg16(pretrained=True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "torch.manual_seed(42)\n",
    "if device == 'cuda':\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Add on classifier\n",
    "model.classifier[6] = nn.Sequential(\n",
    "                      nn.Linear(4096, 256), \n",
    "                      nn.ReLU(), \n",
    "                      nn.Linear(256, 10),                   \n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "for param in model.classifier[6].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00005)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "for epoch in range(4):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data_train in enumerate(trainloader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data_train[0].to(device), data_train[1].to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:    # print every 2000 mini-batches\n",
    "            print(f'epoch: {epoch + 1}\\t iter: {i + 1}\\t loss:{running_loss / 1000:.5f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "evaluate_net(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
